{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc12ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d834b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create questions csv\n",
    "category = \"anatomy\"\n",
    "ds = load_dataset(\"edinburgh-dawg/mmlu-redux\", category)\n",
    "with open('questions.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['question_idx', 'question', 'answer_choices', 'prompt', 'correct_answer', 'category'])\n",
    "    for i, ex in enumerate(ds['test']):\n",
    "        prompt = ex['question'] + \"\\n\\n\" + \"Answer Choices:\\n\" + \"\\n\".join(ex['choices'])\n",
    "        writer.writerow([i, ex['question'], ex['choices'], prompt, ex['answer'], category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc78627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseekr1_0528_tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-0528\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming DeepSeek-R1-0528_mmlu-redux_results.csv exists with the following columns:\n",
    "# question_idx, question, answer_choices, full_prompt, correct_answer, full_cot, predicted_answer, category\n",
    "\n",
    "early_decoders = [\n",
    "    \"probe_model_answer_correct\", \"probe_model_answer\", \"probe_correct_answer\",\n",
    "    \"observer_model_answer_correct\", \"observer_model_answer\", \"observer_correct_answer\",\n",
    "]\n",
    "\n",
    "def generate_fake_data(early_decoder):\n",
    "    if early_decoder.endswith('model_answer_correct'): # did the model answer correctly?\n",
    "        return np.random.dirichlet(np.ones(2)).tolist()\n",
    "    elif early_decoder.endswith('model_answer'): # what did the model answer?\n",
    "        return np.random.dirichlet(np.ones(4)).tolist() \n",
    "    elif early_decoder.endswith('correct_answer'): # what was the correct answer?\n",
    "        return np.random.dirichlet(np.ones(4)).tolist()\n",
    "\n",
    "questions_df = pd.read_csv('DeepSeek-R1-0528_mmlu-redux_results.csv')\n",
    "for row in questions_df.iterrows():\n",
    "    question_idx = row['question_idx']\n",
    "    question = row['question']\n",
    "    answer_choices = row['answer_choices']\n",
    "    prompt = row['full_prompt']\n",
    "    correct_answer = row['correct_answer']\n",
    "    full_cot = row['full_cot']\n",
    "    predicted_answer = row['predicted_answer']\n",
    "    category = row['category']\n",
    "\n",
    "    for early_decoder in early_decoders:\n",
    "        full_cot_tokens = tokenizer.tokenize(full_cot)\n",
    "        for i, token in enumerate(full_cot_tokens):\n",
    "            token_text = tokenizer.convert_ids_to_tokens(token)\n",
    "            probe_output = generate_fake_data(early_decoder)\n",
    "            writer.writerow([question_idx, token_idx, token_text, early_decoder, probe_output])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
